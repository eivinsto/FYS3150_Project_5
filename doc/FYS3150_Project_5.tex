\documentclass[reprint,english,notitlepage]{revtex4-1}  % defines the basic parameters of the document

% if you want a single-column, remove reprint

% allows special characters (including æøå)
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

%% note that you may need to download some of these packages manually, it depends on your setup.
%% I recommend downloading TeXMaker, because it includes a large library of the most common packages.

\usepackage{physics,amssymb}  % mathematical symbols (physics imports amsmath)
\usepackage{graphicx}         % include graphics such as plots
\usepackage{xcolor}           % set colors
\usepackage{hyperref}         % automagic cross-referencing (this is GODLIKE)
\usepackage{tikz}             % draw figures manually
\usepackage{listings}         % display code
\usepackage{subfigure}        % imports a lot of cool and useful figure commands
\usepackage{cprotect}
\usepackage{float}


% defines the color of hyperref objects
% Blending two colors:  blue!80!black  =  80% blue and 20% black
\hypersetup{ % this is just my personal choice, feel free to change things
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}}
%
%% Defines the style of the programming listing
%% This is actually my personal template, go ahead and change stuff if you want
\lstnewenvironment{python}{
	\lstset{ %
		inputpath=,
		backgroundcolor=\color{white!88!black},
		basicstyle={\ttfamily\scriptsize},
		commentstyle=\color{magenta},
		language=Python,
		morekeywords={True,False},
		tabsize=4,
		stringstyle=\color{green!55!black},
		frame=single,
		keywordstyle=\color{blue},
		showstringspaces=false,
		columns=fullflexible,
		keepspaces=true}
}{}

\lstnewenvironment{cpp}{
	\lstset{ %
		inputpath=,
		backgroundcolor=\color{white!88!black},
		basicstyle={\ttfamily\scriptsize},
		commentstyle=\color{magenta},
		language=C++,
		morekeywords={True,False},
		tabsize=4,
		stringstyle=\color{green!55!black},
		frame=single,
		keywordstyle=\color{blue},
		showstringspaces=false,
		columns=fullflexible,
		keepspaces=true}
}{}

\lstset{literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
}



\usepackage{thmtools}
\DeclareMathOperator{\nullspace}{Nul}
\DeclareMathOperator{\collspace}{Col}
\DeclareMathOperator{\rref}{Rref}
%%\DeclareMathOperator{\dim}{Dim}

 % "meq": must be equal
\newcommand{\meq}{\overset{!}{=}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\newcommand{\R}{\mathbb{R}}
\newcommand*\Heq{\ensuremath{\overset{\kern2pt L'H}{=}}}
\usepackage{bm}
\newcommand{\uveci}{{\bm{\hat{\textnormal{\bfseries\i}}}}}
\newcommand{\uvecj}{{\bm{\hat{\textnormal{\bfseries\j}}}}}
\DeclareRobustCommand{\uvec}[1]{{%
  \ifcsname uvec#1\endcsname
     \csname uvec#1\endcsname
   \else
    \bm{\hat{\mathbf{#1}}}%
   \fi
}}
\usepackage[binary-units=true]{siunitx}

\makeatletter
\newcommand*{\balancecolsandclearpage}{%
  \close@column@grid
  \cleardoublepage
  \twocolumngrid
}
\makeatother

\newcounter{subproject}
\renewcommand{\thesubproject}{\alph{subproject}}
\newenvironment{subproj}{
\begin{description}
	\item[\refstepcounter{subproject}(\thesubproject)]
}{\end{description}}


\begin{document}
\title{Title}   % self-explanatory
\author{Eivind Støland, Anders P. Åsbø}               % self-explanatory
\date{\today}                             % self-explanatory
\noaffiliation                            % ignore this

\begin{abstract}
Abstract
\end{abstract}

\maketitle                                % creates the title, author, date


\tableofcontents

\section{Introduction} \label{sec:introduction}


\clearpage

\section{Formalism} \label{sec:formalism}

\subsection{Diffusion equation} \label{sec:formalism_diffusion_equation}

By scaling variables, we can write the general diffusion equation as follows:

\begin{align*}
\nabla^2 u(\vec{r},t) = \frac{\partial u(\vec{r},t)}{\partial t} \, , \numberthis \label{eq:3D_diff_eq}
\end{align*}

where $\nabla$ is the spatial derivative, $\vec{r}$ a vector containing spatial coordinates, $t$ is time, and what $u$ is depends on which system we are looking it in particular. This equation can be used to model several physical phenomena, such as mixing of particles, and perhaps most famously heat conductance through the heat equation:

\begin{align*}
\frac{\kappa}{C \rho} \nabla^2 T(\vec{r},t) = \frac{\partial T (\vec{r},t)}{\partial t} \, , \numberthis \label{eq:heat_equation_general}
\end{align*}

where $\kappa$ is the thermal conductivity, $C$ is the specific heat, $\rho$ is the density of the material, and $T$ is the temperature gradient. This is an equation that we will use, and so we need to scale it. Firstly we can define the diffusion constant $D = C\rho/\kappa$. This means we can write the heat equation as:

\begin{align*}
\nabla^2 T(\vec{r},t) &= D \frac{\partial T(\vec{r},t)}{\partial t}
\end{align*}

Now we define the spatial coordinate vector $\vec{r} = \alpha \hat{\vec{r}}$, where $\alpha$ is an arbitrary constant. Substituting this affects the spatial derivative such that the equation now reads:

\begin{align*}
\frac{1}{\alpha^2} \nabla^2 T(\vec{r},t) &= D \frac{\partial T(\vec{r},t)}{\partial t}
\end{align*}  

As $\alpha$ is an arbitrary constant we can now choose it such that $D = 1/\alpha^2$. The equation then reads:

\begin{align*}
\nabla^2 T(\vec{r},t) &= \frac{\partial T(\vec{r},t)}{\partial t} \, ,
\end{align*}

which is just the general diffusion equation we have listed earlier, with $u$ exchanged for $T$. In other words, if we can solve the general diffusion equation, we can also solve the heat equation.

When solving the diffusion equation numerically it is common to scale the spatial coordinates so that $x,y,z \in [0,1]$ if we are using cartesian coordinates. As long as we are looking at a square system, this does not cause any problems for the method outlined earlier, as we can easily model other choices of limits by adding a constant to the spatial coordinate and correctly choosing $\alpha$. We also assume that the initial state and the boundary conditions are known: 

\begin{align*}
u(x,y,z,0) &= f(x,y,z) \\
u(0,y,z,t) &= g(y,z,t) \\
u(1,y,z,t) &= h(y,z,t) \\
u(x,0,z,t) &= k(x,z,t) \\
\vdots 
\end{align*}

and so on for the other coordinates as well.
 
In the following sections we will look at solutions to the diffusion equation in 1D and 2D both numerically and analytically.




\subsection{Analytical solution of diffusion equation in one dimension} \label{sec:formalism_1D_diff_eq_analytical}

In order to find a solution we need to make some assumptions based on the initial and boundary conditions. We assume that:

\begin{align*}
u(x,0) = g(x) \quad 0 < x < L
\end{align*}

and:

\begin{align*}
u(0,t) = u(L,t) = 0 \quad t \geq 0
\end{align*}

The equation wish to solve is the general diffusion equation in one dimension:

\begin{align*}
\frac{\partial^2 u(x,t)}{\partial x^2} &= \frac{\partial u(x,t)}{\partial t}
\end{align*}

In order to proceed we assume separation of variables:

\begin{align*}
u(x,t) &= F(x)G(t) 
\end{align*}

The diffusion equation can then be rewritten:

\begin{align*}
G \frac{\partial^2 F}{\partial x^2} &= F \frac{\partial G}{\partial t} \\
\frac{F''}{F} &= \frac{G'}{G} \, ,
\end{align*}

where we have denoted the derivatives with primes. In the equation above the left-hand side is completely independent of $t$ and the right-hand side is completely independent of $x$. This directly implies that both sides have to be equal to a constant. We define this constant as $-\lambda^2$, which gives us the following differential equations we need to solve:

\begin{align*}
F'' + \lambda^2 F &= 0 \\
G' + \lambda^2 G &= 0
\end{align*}

These have solutions:

\begin{align*}
F(x) &= A \sin (\lambda x) + B \cos ( \lambda x) \\
G(t) &= Ce^{-\lambda^2 t}
\end{align*}

The boundary conditions are satisfied if we set $B = 0$ and $\lambda = n\pi /L$ where $n$ is a positive integer ($n$ can be 0 as well, but this solution is just 0 everywhere and is thus wholly uninteresting). A solution can then be written:

\begin{align*}
u_n(x,t) &= A_n \sin (\frac{n\pi}{L} x ) e^{-\frac{n^2 \pi^2}{L^2} t} \, ,
\end{align*}

where we have included the constants $C$ and $A$ in $A_n$. A general solution will thus be a linear combination of these solutions for all $n$:

\begin{align*}
u(x,t) &= \sum\limits_{n=1}^\infty A_n \sin (\frac{n\pi}{L} x) e^{-\frac{n^2 \pi^2}{L^2} t} 
\end{align*}

We still need to determine the constants $A_n$ and these are given by the initial condition:

\begin{align*}
g(x) &= u(x,0) \\
g(x) &= \sum\limits_{n=1}^\infty A_n \sin ( \frac{n\pi}{L} x) 
\end{align*}

This is the expression for a Fourier expansion of $g(x)$, and we can thus determine the coefficients as:

\begin{align*}
A_n &= \frac{2}{L} \int_0^L g(x) \sin (\frac{n\pi}{L} x) \, dx
\end{align*}

We can also adapt our solution for different boundary conditions. In most cases we assume the the boundary values are constants $u(0,t) = a$, $u(L,t) = b$ where $a$ and $b$ are constants. If we assume there to be a steady state solution $f(x)$ fitting these boundary conditions, then we can write $u(x,t) = v(x,t) + f(x)$, where $v(x,t)$ is the solution of the differential equation when the boundary conditions are zero. The steady state solution is determined by solving the Laplace equation:

\begin{align*}
\frac{\partial^2 f(x)}{\partial x^2} &= 0 
\end{align*}

If the boundary conditions are constant this is simply a linear polynomial of first order:

\begin{align*}
f(x) &= \frac{b-a}{L} x + a
\end{align*}

As this is a first order polynomial, it falls away in the diffusion equation, meaning that the solution for a $u(x,t)$ with general constant boundary conditions can be given as the solution with boundary conditions zero plus the steady state solution of the problem. In other words, the solution is given fully as:

\begin{align*}
u(x,t) &= f(x) + \sum\limits_{n=1}^\infty A_n \sin( \frac{n\pi}{L} x) e^{-\frac{n^2 \pi^2}{L^2} t}
\end{align*}

Finding the coefficients turns out slightly different, as we have:

\begin{align*}
g(x) &= u(x,0) \\
g(x) &= f(x) + \sum\limits_{n=1}^\infty A_n \sin( \frac{n\pi}{L} x)
\end{align*}

This is not a simple Fourier expansion, but by defining $h(x) = g(x) - f(x)$ we can rewrite the equation above as:

\begin{align*}
h(x) &= \sum\limits_{n=1}^\infty A_n \sin( \frac{n\pi}{L} x)
\end{align*}

This is a Fourier expansion of $h(x)$, and thus we can find the coefficients:

\begin{align*}
A_n &= \frac{2}{L} \int_0^L h(x) \sin (\frac{n\pi}{L} x) \, dx \, ,
\end{align*}

by using $h(x)$ instead of $g(x)$. 


\subsection{Numerical solutions of one-dimensional diffusion equation} \label{sec:formalism_numerical_1D}

\subsubsection{Euler methods} \label{sec:formalism_euler_methods}

First, we write down the diffusion equation in one dimension:

\begin{align*}
\frac{\partial^2 u(x,t)}{\partial x ^2} &= \frac{\partial u(x,t)}{\partial t} \, , \numberthis \label{eq:1D_diff_eq}
\end{align*}

where $x$ is the spatial coordinate, and other variables are as previously defined. This can be written in the short-hand notation:

\begin{align*}
u_{xx} = u_t \, ,
\end{align*}

where the subscripts denote a partial derivative with respect to the variable in the subscript. The spatial derivative part of this equation can be approximated:

\begin{align*}
u_{xx} &= \frac{u(x + \Delta x,t) - 2u(x,t) + u(x-\Delta x,t)}{\Delta x^2} + \mathcal{O}(\Delta x^2)
\end{align*}

We also need to approximate the time derivative part, and we can do this in one of two ways, either using the forward approximation of the derivative:

\begin{align*}
u_t &= \frac{u(x,t+\Delta t) - u(x,t)}{\Delta t} + \mathcal{O}(\Delta t) \, ,
\end{align*}

or the backwards approximation:

\begin{align*}
u_t &= \frac{u(x,t) - u(x,t-\Delta t)}{\Delta t} + \mathcal{O}(\Delta t) \, .
\end{align*}

We can discretize the equations by first defining a steplength:

\begin{align*}
\Delta x = \frac{1}{n+1} \, ,
\end{align*}

and a timestep $\Delta t$, and then defining a set of points for both $x$ and $t$ given by the subscripts $i$ and $j$ respectively:

\begin{align*}
x_i &= i \Delta x \quad 0 \leq i \leq n+1 \\
t_j &= j \Delta t \quad 0 \leq j \, ,
\end{align*}

with both $i,j$ being positive integers or zero. By denoting $u$ with subscripts $i$ and $j$ we can thus express which set of $x$ and $t$ it is evaluated at. We can then rewrite the spatial approximation:

\begin{align*}
u_{xx} &\approx \frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{\Delta x^2} \, ,
\end{align*}

the forward time approximation:

\begin{align*}
u_t &\approx \frac{u_{i,j+1} - u_{i,j}}{\Delta t} \, ,
\end{align*}

and the backwards time approximation:

\begin{align*}
u_t &\approx \frac{u_{i,j}- u_{i,j-1}}{\Delta t}
\end{align*}

Now, we set up the diffusion equation using the forward approximation in time first:

\begin{align*}
u_t &= u_{xx} \\
\frac{u_{i,j+1} - u_{i,j}}{\Delta t} &= \frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{\Delta x^2}  \\
u_{i,j+1} &= u_{i,j} + \frac{\Delta t}{\Delta x^2} \bigg( u_{i+1,j} - 2u_{i,j} + u_{i-1,j} \bigg) \\
u_{i,j+1} &= u_{i,j} + \alpha \bigg( u_{i+1,j} - 2u_{i,j} + u_{i-1,j} \bigg) \, ,\numberthis \label{eq:forward_euler_method}
\end{align*}

where $\alpha = \Delta t /\Delta x^2$ (not to be confused with the constant used earlier). It is clear that if we know the initial state and boundary conditions of this system that we can move the system ahead in time using the equation above. At this point we make the assumption that the boundary conditions are zero. By the arguments given in \ref{sec:formalism_1D_diff_eq_analytical} this can easily be extended to constant boundary conditions by use of the steady state solution of the problem. Implementing a numerical solution for other boundary conditions is not difficult, as the only requirement we must have is that the solver cannot modify the boundary values outside of the boundary condition specified. Assuming Dirichlet boundary conditions simplify the calculaton of the condition for convergence, and so we keep them in this section.

The equation above gives directly the solution in the next timestep, and thus this is an explicit scheme. This can also be rewritten as a matrix vector equation by using $U_j = [u_{1,j} \quad u_{1,j} \quad ... \quad u_{n,j} ] ^T$. And the matrix:

\begin{align*}
A_\text{f} &= \begin{bmatrix}
1 - 2\alpha & \alpha & 0   &\cdots & 0 \\
\alpha & 1-2\alpha & \alpha   & \cdots & 0 \\
\vdots & \ddots & \ddots & \ddots  & \vdots \\
0 & \cdots  & \alpha & 1 - 2\alpha & \alpha \\
0 & \cdots & 0 & \alpha & 1 - 2\alpha 
\end{bmatrix} \, ,
\end{align*}

where the subscript f denotes that this is the scheme based on the forward Euler method. This gives us that the explicit scheme can be described by the matrix-vector equation:

\begin{align*}
U_{j+1} &= A_\text{f} U_{j}
\end{align*}

Note that if we know the solution at a previous timestep $U_j$ we can directly determine the solution in the next timestep $U_{j+1}$, and thus we do not need to solve this matrix-vector equation per se. It is just a practical way of denoting things that we will get back to. The vector $U_j$ does not contain the boundary elements $u_{0,j}$ and $u_{n+1,j}$ as they are generally assumed to be zero.

Using the backwards time approximation in a similar fashion gives us the following: 

\begin{align*}
u_t &= u_{xx} \\ 
\frac{u_{i,j} - u_{i,j-1}}{\Delta t} &= \frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{\Delta x^2} \\
u_{i,j-1} &= u_{i,j} - \frac{\Delta t}{\Delta x^2} \bigg( u_{i+1,j} - 2u_{i,j} + u_{i-1,j} \bigg) \\
u_{i,j-1} &= u_{i,j} - \alpha \bigg( u_{i+1,j} - 2u_{i,j} + u_{i-1,j} \bigg) \numberthis \label{eq:backward_euler_method}
\end{align*}

As we cannot directly determine the solution in the next timestep from this equation, this is an implicit scheme, and we must formulate a way we can solve this equation. We can write down the above equation as a matrix-vector equation by using the same vector $U_j$ as earlier and the matrix:

\begin{align*}
A_\text{b} &= \begin{bmatrix}
1 + 2\alpha & -\alpha & 0   &\cdots & 0 \\
-\alpha & 1+2\alpha & -\alpha   & \cdots & 0 \\
\vdots & \ddots & \ddots & \ddots  & \vdots \\
0 & \cdots  & -\alpha & 1 + 2\alpha & -\alpha \\
0 & \cdots & 0 & -\alpha & 1 + 2\alpha 
\end{bmatrix} \, , 
\end{align*} 

where the subscript b denotes that this is the matrix based on the backwards Euler method. This gives us the matrix-vector equation:

\begin{align*}
U_{j-1} &= A_\text{b} U_j \\
A_\text{b}^{-1} &= U_j
\end{align*}


In order to determine the solution in the next timestep $j$ it is thus necessary to solve this matrix-vector equation. This can be done in a multitude of ways, but the simplest way of solving this is that this matrix is tridiagonal if we exclude the boundaries. Thus we can use a solver for a tridiagonal matrix, as long as we handle the boundaries correctly as a special case. Solving the equation as such greatly reduces the computational cost of solving the problem compared to a general matrix inversion.

We also wish to examine the convergence of these schemes. By defining the matrix:

\begin{align*}
B &= \begin{bmatrix}
2 & -1 & 0 & \cdots & 0 \\
-1 & 2 & -1 &  \cdots & 0 \\
\vdots & \ddots & \ddots & \ddots & \vdots \\
\vdots & \vdots & \ddots & \ddots & -1 \\
0 & 0 & \cdots & -1 & 2 
\end{bmatrix} \, ,
\end{align*}

we can rewrite $A_\text{f} = I - 2B$ and $A_\text{b} = I + 2B$. First we look at the explicit scheme.

For the solution to converge we need the spectral radius to be less than one. The spectral radius of a matrix is the absolute of the largest eigenvalue of the matrix. Thus we need to find the eigenvalues of $A_\text{f}$, $\lambda$. Since $A_\text{f} = I - \alpha B$ it is obvious that it has eigenvalues $\lambda_{k} = 1 - \alpha \mu_k$ where $\mu$ are the eigenvalues of $B$ and the subscript $k$ denotes which eigenvalue we are looking at. The eigenvalues of $B$ are (\cite[p.~307]{Hjorth-Jensen2015}):

\begin{align*}
\mu_k = 2 - 2\cos(\frac{k\pi}{n} + 1) \, , 
\end{align*}

where $n$ is as defined earlier. The requirement for the solution to converge is that the spectral radius $\rho(A_\text{f})$:

\begin{align*}
\rho(A_\text{f}) &< 1 \\
|\max (\lambda_k) | &< 1 \\
|\max ( 1 - 2\alpha(1 - \cos (\frac{k\pi}{n} + 1) ) | &< 1
\end{align*}

This is only the case if:

\begin{align*}
2\alpha ( 1 - \cos( \frac{k\pi}{n} + 1) ) &< 2 \\
\alpha &< ( 1 - \cos( \frac{k\pi}{n} + 1) )^{-1} 
\end{align*}

The right-hand side can never be smaller than $1/2$, which gives us that $\alpha$ has to be less than $1/2$ in order for the solution to converge. The condition for convergence with the explicit scheme is thus:

\begin{align*}
\frac{\Delta t}{\Delta x^2} &\leq \frac{1}{2} \, , \numberthis \label{eq:forward_euler_convergence}
\end{align*}

In order to determine the condition for convergence with the implicit scheme we need that $\rho(A_\text{b}^{-1}) < 1$. This is the case if $\rho(A_\text{b}) > 1$. As we can write $A_\text{b} = I + 2B$, we can infer that the eigenvalues of $A_\text{b}$ are $\lambda_k = 1 + 2\alpha \mu_k = 1 + 2\alpha (1 - \cos(k\pi/n + 1) )$ which is always greater than one. Thus the spectral radius $\rho(A_\text{b})$ is always greater than one, and the solutions converges for any choice of $\alpha$. 


\subsubsection{Crank-Nicolson scheme} \label{sec:formalism_crank_nicolson}

The two schemes outlined above can be combined into a single scheme using a parameter $\theta$:

\begin{align*}
\frac{\theta}{\Delta x^2} \bigg( u_{i-1,j} - 2u_{i,j} + u_{i+1,j} \bigg) &+ \frac{1 - \theta}{\Delta x^2} \bigg( u_{i+1,j-1} \\
- 2u_{i,j-1} + u_{i-1,j-1} \bigg) &= \frac{1}{\Delta t} \bigg( u_{i,j} - u_{i,j-1} \bigg) \numberthis \label{eq:theta_rule}
\end{align*}

We recognize that by setting $\theta=0$ this returns the explicit scheme, and that it returns the implicit scheme when $\theta = 1$. If we set $\theta = 1/2$, however, we get what is called the Crank-Nicholson scheme. By using $\alpha = \Delta t / \Delta x^2$ we can in this case rewrite the equation above as:

\begin{align*}
&-\alpha u_{i-1,j} + (2 + 2 \alpha) u_{i,j} - \alpha u_{i+1,j} \\
&= \alpha u_{i-1,j-1} + (2-2\alpha) u_{i,j-1} + \alpha u_{i+1,j-1} \numberthis \label{eq:crank_nicholson}
\end{align*}

For the full derivation of this scheme we refer to \cite[p.~311]{Hjorth-Jensen2015}. It is derived from approximating around a midpoint $t' = t + \Delta t/2$, which gives that the error from the time approximation goes as $\mathcal{O}(\Delta t^2)$ instead of $\mathcal{O}(\Delta t)$. The spatial approximation still results in an error $\mathcal{O}(\Delta x^2)$, however.

Equation \eqref{eq:crank_nicholson} can be rewritten as a matrix-vector equation using the identity matrix $I$, the matrix $B$ and the vector $U_j$ as defined in the previous section, and by assuming Dirichlet boundary conditions:

\begin{align*}
(2I + \alpha B ) U_j &= (2I - \alpha B) U_{j-1} \\
U_j &= (2I + \alpha B)^{-1} (2I - \alpha B) u_{j-1}
\end{align*}

In other words a matrix inversion is required in order to find the solution in the next timestep. This means that this scheme is an implicit one. First we need to multiply the previous solution with the matrix $(2I - \alpha B)$, which is straightforward. After that we need to find the inverse of $(2I + \alpha B)$ and apply this. As this matrix is tridiagonal we can use a tridiagonal solver for this operation. Thus the numerical solution of this scheme can be split into two parts, one which functions similar to the way in which the solver for the forward Euler based explicit scheme, and a second part that functions similarly to the solver for the backwards Euler based implicit scheme.

The solution with the Crank-Nicholson scheme converges if the spectral radius:

\begin{align*}
\rho\bigg( (2I + \alpha B)^{-1} (2I - \alpha B) \bigg) < 1 \, .
\end{align*}

This is the case if:

\begin{align*}
| \frac{2 - \alpha \mu_k}{2 + \alpha \mu_k} | < 1
\end{align*}

As $\mu_k = 2 - 2 \cos(k\pi/n + 1)$ is always positive this condition is always met, and thus the Crank-Nicholson scheme also converges for any $\alpha$. 




\subsection{Analytical solution of diffusion equation in two dimensions} \label{sec:formalism_2D_diff_eq_analytical}

The equation we wish to solve is to two-dimensional diffusion equation:

\begin{align*}
\frac{\partial^2 u(x,y,t)}{\partial x^2} + \frac{\partial^2 u(x,y,t)}{\partial y^2} &= \frac{\partial u(x,y,t)}{\partial t}
\end{align*}

We wish to solve for a square system, with $x,y \in [0,L]$. We assume a general initial state $u(x,y,0) = g(x,y)$ and Dirichlet boundary conditions $u(0,y,t) = u(L,y,t) = u(x,0,t) = u(x,L,t) = 0$. We assume separation of variables:

\begin{align*}
u(x,y,t) = F(x,y) G(t)
\end{align*}

The diffusion equation then gives:

\begin{align*}
G\bigg( \frac{\partial^2 F}{\partial x^2} + \frac{\partial^2 F}{\partial y^2} \bigg) &= F\frac{\partial G}{\partial t} \\
GF'' &= FG'\\
\frac{F''}{F} &= \frac{G'}{G} \numberthis \label{eq:2D_separation_of_variables_step1} \, ,
\end{align*}

where:

\begin{align*}
F'' &= \frac{\partial^2 F}{\partial x^2} + \frac{\partial^2 F}{\partial y^2} \\
G' &= \frac{\partial G}{\partial t}
\end{align*}

In equation \eqref{eq:2D_separation_of_variables_step1} the right-hand side and left-hand side do not share any variables, and thus they must be constant. We define this constant as $-\lambda^2$. This gives us the differential equations:

\begin{align*}
F'' + \lambda^2 F &= 0 \\
G' + \lambda^2 G &= 0
\end{align*}

The second of these has the familiar solution:

\begin{align*}
G(t) = Ee^{-\lambda^2 t} \, ,
\end{align*}

where $E$ is an integration constant. The first differential equation is not as easy to solve, but we can do it by again assuming separation of variables in $F$:

\begin{align*}
F(x,y) &= X(x) Y(y)
\end{align*}

Inserting this into the differential equation gives:

\begin{align*}
F'' &= -\lambda^2 F \\
Y \frac{\partial^2 X}{\partial x^2} + X \frac{\partial^2 Y}{\partial y^2} &= -\lambda^2 XY \\
\frac{X''}{X} +  &= - \frac{Y''}{Y} - \lambda^2 \, ,
\end{align*}

where:

\begin{align*}
X'' &= \frac{\partial^2 X}{\partial x^2} \\
Y'' &= \frac{\partial^2 Y}{\partial y^2}
\end{align*}

As $X$ is only dependent on $x$ and $Y$ only dependent on $y$, this means that:

\begin{align*}
\frac{X''}{X} &= - \frac{Y''}{Y} - \lambda^2 &= \text{constant}
\end{align*}

We define this constant to be $-\mu^2$. And we also define $\nu^2 = \lambda^2 - \mu^2$. This gives us the following set of differential equation:

\begin{align*}
X'' + \mu^2 X &= 0 \\
Y'' + \nu^2 Y &= 0 \, ,
\end{align*}  

which have solutions:

\begin{align*}
X(x) &= A \sin(\mu x) + B\cos(\mu x) \\
Y(y) &= C \sin (\nu y) + D \cos (\nu y)
\end{align*}

The boundary conditions imply that $B=D=0$, and that $\mu = n\pi/L$ and $\nu = m\pi/L$, where $n$ and $m$ are positive integers. We also have that $\lambda^2 = \nu^2 + \mu^2 = (n^2+m^2) \pi^2/L^2$. This gives us that a solution of the diffusion equation in two dimensions can be written as:

\begin{align*}
u_{n,m}(x,y,t) = A_{n,m} \sin (\frac{n\pi}{L} x)  \sin (\frac{m\pi}{L} y) e^{-\frac{(n^2 + m^2)\pi^2}{L^2} t} \, ,
\end{align*}

where the coefficients $A_{n,m}$ include the constants $A$, $C$ and $E$. A general solution can be written as a linear combination of these (sum over all $n$ and $m$):

\begin{align*}
u(x,y,t) &= \sum\limits_{n=1}^\infty \sum\limits_{m=1}^\infty A_{n,m} \sin (\frac{n\pi}{L} x)  \sin (\frac{m\pi}{L} y) e^{-\frac{(n^2 + m^2)\pi^2}{L^2} t} \numberthis \label{eq:2D_diffusion_equation_analytical_solution}
\end{align*} 

In order to find an expression for the coefficients $A_{n,m}$ we first write down the initial state of the system:

\begin{align*}
g(x,y) &= u(x,y,0) \\
g(x,y) &= \sum\limits_{n=1}^\infty \sum\limits_{m=1}^\infty A_{n,m} \sin (\frac{n\pi}{L} x)  \sin (\frac{m\pi}{L} y)
\end{align*}

Similarly to the one-dimensional case, this is reminiscent of a Fourier transform. As $x$ and $y$ are independent, we can find the coefficients $A_{n,m}$ as:

\begin{align*}
A_{n,m} &= \frac{4}{L^2} \int_0^L \int_0^L g(x,y) \sin( \frac{n\pi}{L} x) \sin (\frac{m\pi}{L} y) \, dx \, dy \numberthis \label{eq:2D_diffusion_equation_analytical_coefficients}
\end{align*}

This lets us determine the analytical solution in two dimensions for any initial state $g(x,y)$ such that this integral is solvable, with Dirichlet boundary conditions.

Again, similarly to the one dimensional case, we can extend this solution for general time-independent boundary conditions. If the boundary conditions are independent of time we can simply add the steady-state function of that system to the solution with Dirichlet boundary conditions:

\begin{align*}
u(x,y,t) = v(x,y,t) + f(x,y) \, ,
\end{align*}

where $v(x,y,t)$ is the solution with Dirichlet boundary conditions, and $f(x,y)$ is the steady state solution. The steady state solution must fulfill the Laplace equation:

\begin{align*}
\nabla^2 f(x,y) &= 0 \, ,
\end{align*}

constrained by the boundary conditions specified. As long as the Laplace equation holds for the steady state solution, it is easy to the see that adding it to $v(x,y,t)$ does not disturb the diffusion equation:

\begin{align*}
\nabla^2 u(x,y,t) &= \frac{\partial u(x,y,t)}{\partial t} \\
\nabla^2 (v(x,y,t) + f(x,y) ) &= \frac{\partial v(x,y,t)}{\partial t} + \frac{\partial f(x,y)}{\partial t} \\
\nabla^2 v(x,y,t) &= \frac{\partial v(x,y,t)}{\partial t} \, ,
\end{align*}

where we have used that the Laplace equation holds for $f(x,y)$ and that it is independent of time. Finding a general steady state solution is not as easy as in the one-dimensional case, however, as the boundaries need to be well defined at the corners. In order for this to be the case, the boundary conditions for at least one of the spatial coordinates has to depend on the other spatial coordinate if we assume the boundary values to be non-zero. 



\clearpage

\section{Method} \label{sec:method}

\clearpage

\section{Results} \label{sec:results}

\clearpage

\section{Discussion} \label{sec:discussion}

\clearpage



\section{Conclusion} \label{sec:conclusion}

\onecolumngrid
\bibliography{kilder.bib}{}
\newpage
\twocolumngrid

\appendix
\section{Source code} \label{A}
All code for this report was written in C++ and Python 3.6, and the complete set of files can be found at:

\url{https://github.com/eivinsto/FYS3150_Project_5.git}.

\cprotect\subsection{temp} \label{A.1}

\clearpage
\section{Selected results} \label{B}
Here is a folder of selected results from running our code.

\url{https://github.com/eivinsto/FYS3150_Project_5/tree/master/data}

\newpage
\section{System specifications} \label{C}
All results included in this report were achieved by running the implementation on the following system:

\begin{itemize}
	\item CPU: AMD Ryzen \(9\) \(3900\)X \\
		- \(12\) cores, \(24\) threads. \\ 
		- \(\SI{3.8}{\giga\hertz}\) base clock. \\
		- \(\SI{4.2}{\giga\hertz}\) all core boost clock. \\
		- \(\SI{4.6}{\giga\hertz}\) single core boost clock. \\
	\item RAM: \(2\times\SI{8}{\giga\byte}\) Corsair Vengeance LPX DDR\(4\) \(\SI{3200}{\mega\hertz}\)
\end{itemize}

\end{document}
